[{"authors":["xiaoou"],"categories":null,"content":"Thème\nSur fond de tension entre la Chine et les Etats-Unis, nous nous sommes penchés sur la représentation de la guerre commerciale sur la toile des pays anglophones, de la Chine, et de la France.\nMotivation\nLa guerre commerciale est susceptible de causer une récession générale. Les Etats-Unis semblent considérer que la montée de la Chine menace déjà son hégémonie, alors que la Chine, aspirant à des progrès économiques toujours plus importants, prennent la défense de ses propres intérêts.\nExclusivités\n Syntaxe highlighting  Tous les codes sont colorés pour faciliter la lecture, que cela soit Python, Javascript, Perl ou Shell (bash).\n Recherche productible  Nos codes sont écrits dans des fichiers .Rmd. Il suffit de les ouvrir dans Rstudio pour les exécuter et voir ainsi les résultats.\n Git  L\u0026rsquo;historique de notre projet est intégralement conservée et documentée grâce à Git, logiciel de gestion de versions décentralisé. Les codes Rmarkdown se trouvent ici et les codes du site ici.\n Responsive Design  Notre site s\u0026rsquo;adapte automatiquement à différentes tailles d\u0026rsquo;écran.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"51b9199d1441fa523628dd4669da1c42","permalink":"/projet_encadre/authors/xiaoou/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/projet_encadre/authors/xiaoou/","section":"authors","summary":"Thème\nSur fond de tension entre la Chine et les Etats-Unis, nous nous sommes penchés sur la représentation de la guerre commerciale sur la toile des pays anglophones, de la Chine, et de la France.\nMotivation\nLa guerre commerciale est susceptible de causer une récession générale. Les Etats-Unis semblent considérer que la montée de la Chine menace déjà son hégémonie, alors que la Chine, aspirant à des progrès économiques toujours plus importants, prennent la défense de ses propres intérêts.","tags":null,"title":"ô la guerre, quand tu nous tiens !","type":"authors"},{"authors":null,"categories":null,"content":" Navigation A gauche vous trouvez la liste des billets écrits après chaque cours\nA droite vous avez accès au sommaire de chaque billet.\nPour vous faciliter la navigation, nous avons également mis à disposition la liste des billets sur cette page.\nListe des billets  cours 2 - Préambule Unix I cours 3 - Préambule Unix II cours 4 - Préparation du projet cours 6 - Détection de l’encodage d’URL cours 7 - Rajouter 4 colonnes dans la table d\u0026rsquo;URLs cours 8 - Résolution du problème d\u0026rsquo;encodage cours 9 - deuxième méthode pour la segmentation du corpus chinois cours 10 - Reconstruction du code (Refactoring)  ","date":1546642800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1546642800,"objectID":"b0d8ccffb8d530bff08365a148a04ee6","permalink":"/projet_encadre/blog/","publishdate":"2019-01-05T00:00:00+01:00","relpermalink":"/projet_encadre/blog/","section":"blog","summary":" Navigation A gauche vous trouvez la liste des billets écrits après chaque cours\nA droite vous avez accès au sommaire de chaque billet.\nPour vous faciliter la navigation, nous avons également mis à disposition la liste des billets sur cette page.\nListe des billets  cours 2 - Préambule Unix I cours 3 - Préambule Unix II cours 4 - Préparation du projet cours 6 - Détection de l’encodage d’URL cours 7 - Rajouter 4 colonnes dans la table d\u0026rsquo;URLs cours 8 - Résolution du problème d\u0026rsquo;encodage cours 9 - deuxième méthode pour la segmentation du corpus chinois cours 10 - Reconstruction du code (Refactoring)  ","tags":null,"title":"Mode d'emploi","type":"docs"},{"authors":null,"categories":null,"content":"Système de fichiers\nSous windows, il y a plusieurs arborescences tandis que sous unix, on a qu’une arborescence. pwd # print repertoire actuel cd .. # remonte au repertoire parent cd / # aller a la racine echo \u0026quot;# exemple de l'arborescence de la racine sous Mac\u0026quot; ls # exemple de l'arborescence de la racine sous Mac cd ~ # aller a home echo \u0026quot;# sortie de la commande cat\u0026quot; echo \u0026quot;Bonjour\u0026quot; \u0026gt; test.txt cat test.txt # visualiser le contenu d'un fichier echo \u0026quot;# montrer les metadonnes du contenu\u0026quot; wc test.txt # la commande egale wc -mlw, m = caractere l = ligne, w = mots  /Users/becca/Downloads/siteProjetEncadre/content/blog # exemple de l'arborescence de la racine sous Mac Applications Developer Incompatible Software Library Network System Users Volumes anaconda3 bin cores dev etc home installer.failurerequests net opt private sbin tmp usr var # sortie de la commande cat Bonjour # montrer les metadonnes du contenu 1 1 8 test.txt  ","date":1569967200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569967200,"objectID":"6e16f9795c5b0f83798e56ef0528f59c","permalink":"/projet_encadre/blog/1/","publishdate":"2019-10-02T00:00:00+02:00","relpermalink":"/projet_encadre/blog/1/","section":"blog","summary":"Système de fichiers\nSous windows, il y a plusieurs arborescences tandis que sous unix, on a qu’une arborescence. pwd # print repertoire actuel cd .. # remonte au repertoire parent cd / # aller a la racine echo \u0026quot;# exemple de l'arborescence de la racine sous Mac\u0026quot; ls # exemple de l'arborescence de la racine sous Mac cd ~ # aller a home echo \u0026quot;# sortie de la commande cat\u0026quot; echo \u0026quot;Bonjour\u0026quot; \u0026gt; test.","tags":null,"title":"Cours 2 - Préambule Unix I","type":"docs"},{"authors":null,"categories":null,"content":"1. Flux d\u0026rsquo;entrée \u0026amp; de sortie \u0026amp; d\u0026rsquo;erreur\n# flux d’erreur standard \u0026quot;\u0026gt;\u0026gt;\u0026quot; (sortie normal) vs. 2\u0026gt; (canal d’erreur) cd ~ lsd \u0026gt; sortie.txt 2\u0026gt; erreur.txt # exercice : transformer tous les n en N d'un fichier et l'enregistrer dans un autre fichier tr \u0026quot;n\u0026quot; \u0026quot;N\u0026quot; \u0026lt; test.txt \u0026gt; testN.txt cat testN.txt # Exercice : majusculiser les données tr \u0026quot;[[:lower:]]\u0026quot; \u0026quot;[[:upper:]]\u0026quot; \u0026lt; test.txt  BoNjour BONJOUR  2. Redirection du flux d’information Récupérer l’output de la première commande et le réenvoyer à la deuxième commande - symbole clé : pipe |\n# transformer \u0026quot;é\u0026quot; en \u0026quot;E\u0026quot; puis majusculiser l'output de la première commande cd ~ tr \u0026quot;é\u0026quot; \u0026quot;E\u0026quot; \u0026lt; test.txt | tr \u0026quot;[[:lower:]]\u0026quot; \u0026quot;[[:upper:]]\u0026quot; # trier par le premier champ - sort ; filtrage de doublons - uniq egrep -o \u0026quot;\\w+\u0026quot; test.txt | sort | uniq -c  BONJOUR 1 Bonjour  3. Sectionner les données par champ (un champ est defini par un symbole qui delimite ce champ particulier)\n# couper les données en 2 champs par le délimiteur \u0026quot;=\u0026quot; cd ~ echo \u0026quot;la somme de 2+2=4\u0026quot; \u0026gt; test2.txt cut -f2 -d\u0026quot;=\u0026quot; test2.txt # utiliser read pour capturer la saisie de l'utilisateur et la stocker dans une variable echo \u0026quot;nom ?\u0026quot; ; # read nom; echo \u0026quot;bonjour $nom\u0026quot;  4 nom ? bonjour  nom ?\nwang\nbonjour wang\n","date":1569967200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569967200,"objectID":"23189ba8a1714c94f6dfaf5b36cdaffa","permalink":"/projet_encadre/blog/2/","publishdate":"2019-10-02T00:00:00+02:00","relpermalink":"/projet_encadre/blog/2/","section":"blog","summary":"1. Flux d\u0026rsquo;entrée \u0026amp; de sortie \u0026amp; d\u0026rsquo;erreur\n# flux d’erreur standard \u0026quot;\u0026gt;\u0026gt;\u0026quot; (sortie normal) vs. 2\u0026gt; (canal d’erreur) cd ~ lsd \u0026gt; sortie.txt 2\u0026gt; erreur.txt # exercice : transformer tous les n en N d'un fichier et l'enregistrer dans un autre fichier tr \u0026quot;n\u0026quot; \u0026quot;N\u0026quot; \u0026lt; test.txt \u0026gt; testN.txt cat testN.txt # Exercice : majusculiser les données tr \u0026quot;[[:lower:]]\u0026quot; \u0026quot;[[:upper:]]\u0026quot; \u0026lt; test.txt  BoNjour BONJOUR  2. Redirection du flux d’information Récupérer l’output de la première commande et le réenvoyer à la deuxième commande - symbole clé : pipe |","tags":null,"title":"Cours 3 - Préambule Unix II","type":"docs"},{"authors":null,"categories":null,"content":"Configuration du terrain   Nous avons créé l\u0026rsquo;arborescence de travail à l\u0026rsquo;aide du script bash suivant nommé \u0026lsquo;prepare-environnement-projet.sh\u0026rsquo;\n#!/bin/bash mkdir PROJET_MOT_SUR_LE_WEB cd PROJET_MOT_SUR_LE_WEB # on peut desormais creer l'arborescence de travail mkdir ./CONTEXTES; mkdir ./DUMP_TEXT; mkdir ./IMAGES; mkdir ./PAGES_ASPIREES; mkdir ./PROGRAMMES; mkdir ./TABLEAUX; mkdir ./URLS; # les lignes precedentes peuvent tenir sur une seule ligne # a savoir mkdir ./CONTEXTES ./DUMP_TEXT etc.... # le dossier URLS contiendra le fichier initial d'URLs  Il suffit de nous positionner dans le même répertoire que ce script et l\u0026rsquo;exécuter avec bash\nbash prepare-environnement-projet.sh   Etape 1 : lire les fichiers URL et écrire leurs contenus ligne par ligne dans un nouveau fichier J\u0026rsquo;ai une remarque sur la manière dont on utilise pour récupérer tous les fichiers dans un répertoire. J\u0026rsquo;ai utilisé /chemin/* au lieu de $(ls /chemin) car ce dernier m\u0026rsquo;apparaît un peu lourd mais je vois pas leur différence au niveau de sortie\n# !/bin/bash # on commence par effacer l'éventuel contenu de ficher que l'on doit réécrire echo \u0026quot;\u0026quot; \u0026gt; \u0026quot;$2/tableau.html\u0026quot;; # on récupère les 2 arguments que l'on a passé au programme # le premier : chemin vers le dossier contenant les fichiers d'URL # le second : chemin vers le dossier devant contenir le fichier HTML final echo \u0026quot;les urls sont dans : $1\u0026quot;; echo \u0026quot;chemin de stockage : $2\u0026quot;; # pour tous les fichiers dans le répertoire 1 for fichier in $1/* # on exécute les commandes suivantes do # compteur destiné à compter les URLs pour chaque fichier d'URL compteur=1; echo \u0026quot;$fichier\u0026quot;; for ligne in $(cat \u0026quot;$fichier\u0026quot;) do echo \u0026quot;$compteur : $ligne\u0026quot; \u0026gt;\u0026gt; \u0026quot;$2/tableau.html\u0026quot;; # on incrémente le compteur des URLs compteur=$((compteur+1)) done done  ","date":1570572000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570572000,"objectID":"f330f6efe29e9f6d880fd39a21d463e9","permalink":"/projet_encadre/blog/3/","publishdate":"2019-10-09T00:00:00+02:00","relpermalink":"/projet_encadre/blog/3/","section":"blog","summary":"Configuration du terrain   Nous avons créé l\u0026rsquo;arborescence de travail à l\u0026rsquo;aide du script bash suivant nommé \u0026lsquo;prepare-environnement-projet.sh\u0026rsquo;\n#!/bin/bash mkdir PROJET_MOT_SUR_LE_WEB cd PROJET_MOT_SUR_LE_WEB # on peut desormais creer l'arborescence de travail mkdir ./CONTEXTES; mkdir ./DUMP_TEXT; mkdir ./IMAGES; mkdir ./PAGES_ASPIREES; mkdir ./PROGRAMMES; mkdir ./TABLEAUX; mkdir ./URLS; # les lignes precedentes peuvent tenir sur une seule ligne # a savoir mkdir ./CONTEXTES ./DUMP_TEXT etc.... # le dossier URLS contiendra le fichier initial d'URLs  Il suffit de nous positionner dans le même répertoire que ce script et l\u0026rsquo;exécuter avec bash","tags":null,"title":"Cours 4 - Préparation du projet","type":"docs"},{"authors":null,"categories":null,"content":"Pour conclure ce que nous avons fait les trois dernières séances :  Nous avons établi d’abord des tables de base contenant des URLs. Ce qui est réalisé à l’aide de deux boucles for, une pour parcourir tous nos fichiers d’URLs et construire une table pour chaque fichier, soit chaque langue ainsi que la deuxième servant à lire les URLs et les écrire dans nos tables ligne à ligne. Nous avons appris que le shell utilise des variables d’environnement dont l’on peut faire apparaître le contenu avec le signe dollars “$”. En utilisant ce signe, nous pouvons stocker et réutiliser le numéro de ligne et le contenu de ligne.\n Ayant pour but de scrap le contenu de page web et faire éventuellement des analyses textuelles au-dessus, nous avons utiliser les commandes curl et lynx. Deux nouvelles colonnes ont été rajoutées pour les liens locaux de fichier html et txt dirigés vers le contenu sans format et celui de texte brut de page web.\n Or, ce processus de scrap n’est pas si facile à cause des problèmes d’URLs ou de l’encodage. Nous avons ainsi détecté si le code d’état de page web est 200 qui veut dire le succès de la requête et si l’encodage est UTF-8. Le résultat de ces vérification décide nos prochains processus. Ces deux information ont également été rajoutées dans nos tables.   \nProblèmes rencontrés Je n’ai pas pris conscience de l’influence d’espace dans le script bash jusqu’au moment de l’apparition des informations d’erreurs suivantes :\n[200: command not found # ou [405: command not found  [200==200]: command not found  La première erreur provient de\nif [ $coderetour == 200 ]  J\u0026rsquo;ai utilisé simples crochets et mis des espaces ente $coderetour et 200. Tandis que la deuxième est à cause de\nif [$coderetour==200]  ce qui n\u0026rsquo;obéit pas à la syntaxe du bash que la condition est toujours entourée d’un espace après le crochet d’ouverture et avant le crochet de fermeture. J\u0026rsquo;ai aussi essayé de comprendre la différence entre simples et doubles crochets et j\u0026rsquo;ai trouvé une réponse raisonnable Les conditions à doubles crochets permettent tout ce qu’offrent les conditions à simples crochets et plus, par exemple, elles proposent l’usage du wildcard comme en bash ainsi que des expressions régulières.\nVoici la dernière version de script accompagné des explications de certaines commandes bash dans les commentaire.\n# !/bin/bash # on commence par effacer l'éventuel contenu de ficher que l'on doit réécrire echo \u0026quot;\u0026quot; \u0026gt; \u0026quot;$2/tableau.html\u0026quot;; # ou # rm -f \u0026quot;$2/tableau.html\u0026quot; ; # on récupère les 2 arguments que l'on a passé au programme # le premier : chemin vers le dossier contenant les fichiers d'URL # le second : chemin vers le dossier devant contenir le fichier HTML final echo \u0026quot;les urls sont dans : $1\u0026quot;; echo \u0026quot;chemin de stockage : $2\u0026quot;; # 1. définir le type \u0026lt;html\u0026gt; echo \u0026quot;\u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;meta charset=\\\u0026quot;UTF-8\\\u0026quot;\u0026gt;\u0026lt;title\u0026gt;Tableaux\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body\u0026gt;\u0026quot; \u0026gt;\u0026gt; \u0026quot;$2/tableau.html\u0026quot;; # 2. générer un tableau par fichier d'URL numeroTable=1; # pour tous les fichiers dans le répertoire 1 # for fichier in $1/* for fichier in $(ls $1) # on exécute les commandes suivantes do # compteur destiné à compter les URLs pour chaque fichier d'URL compteur=1; echo \u0026quot;$1/$fichier\u0026quot;; echo \u0026quot;\u0026lt;table border=\\\u0026quot;2\\\u0026quot; align=\\\u0026quot;center\\\u0026quot; width=\\\u0026quot;80%\\\u0026quot;\u0026gt;\u0026quot; \u0026gt;\u0026gt; \u0026quot;$2/tableau.html\u0026quot;; # lecture ligne à ligne des URLs for ligne in $(cat \u0026quot;$1/$fichier\u0026quot;) do # curl ： un outil de transfert de data de ou vers un serveur # options : # -o output file # -s silent, use -S, --show-error in addition to this option to disable progress meter but still show error messages # -I head, fetch the headers only # -L location, if the server reports that the requested page has moved to a different location, this option will make curl redo the request on the new place. # -w write-out, Make curl display information on stdout after a completed transfer coderetour=$(curl -SIL -o tmp.txt -w %{http_code} $ligne); # si coderetour est egale a 200 if [[ $coderetour == 200 ]] then # normaliser la case, tout est en majuscule, comme UTF-8 # supprimer eventuellement la fin de ligne encodage=$(curl -sIL -o toto -w %{content_type} $ligne|cut -f2 -d\u0026quot;=\u0026quot;|tr '[a-z]' '[A-Z]'|tr -d '\\n'); # quand on ouvre un fichier, le reprtoire sera le sien # pour relier $numeroTable et $compteur, '-' marche mais pas '_'????? curl -L -o \u0026quot;../PAGES-ASPIREES/$numeroTable-$compteur.html\u0026quot; \u0026quot;$ligne\u0026quot;; if [[ $encodage == 'UTF-8' ]] then lynx -dump -nolist -assume-charset=$encodage - display-charset=$encodage \u0026quot;../PAGE_ASPIREES/$numeroTable-$compteur.html\u0026quot; \u0026gt; ../DUMP-TEXT/$numeroTable-$compteur.txt; echo \u0026quot;\u0026lt;tr\u0026gt;\u0026lt;td\u0026gt;$compteur\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;$ligne\\\u0026quot; target=\\\u0026quot;_blank\\\u0026quot;\u0026gt;$ligne\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Code_http:$coderetour\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Encodage:$encodage\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../PAGE-ASPIREES/$numeroTable-$compteur.html\\\u0026quot;\u0026gt;$numeroTable-$compteur.html\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../DUMP-TEXT/$numeroTable-$compteur.txt\\\u0026quot;\u0026gt;$numeroTable-$compteur.txt\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026quot; \u0026gt;\u0026gt; \u0026quot;$2/tableau.html\u0026quot;; else # comment savoir si la valeur est connu de iconv # extraction de l'encodage avec egrep dans la page aspiree # lynx dump avec l'encodage trouve # convertir le dump en utf8 avec iconv echo \u0026quot;\u0026lt;tr\u0026gt;\u0026lt;td\u0026gt;$compteur\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;$ligne\\\u0026quot; target=\\\u0026quot;_blank\\\u0026quot;\u0026gt;$ligne\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Code_http:$coderetour\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Encodage:$encodage\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../PAGE_ASPIREES/$numeroTable-$compteur.html\\\u0026quot;\u0026gt;\u0026quot;$numeroTable-$compteur.html\u0026quot;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026quot; \u0026gt;\u0026gt; \u0026quot;$2/tableau.html\u0026quot;; fi else echo \u0026quot;\u0026lt;tr\u0026gt;\u0026lt;td\u0026gt;$compteur\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;$ligne\\\u0026quot; target=\\\u0026quot;_blank\\\u0026quot;\u0026gt;$ligne\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Code_http:$coderetour\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026quot; \u0026gt;\u0026gt; \u0026quot;$2/tableau.html\u0026quot;; fi compteur=$((compteur+1)); done echo \u0026quot;\u0026lt;/table\u0026gt;\u0026lt;br /\u0026gt;\u0026quot; \u0026gt;\u0026gt; \u0026quot;$2/tableau.html\u0026quot;; # cat $fichier \u0026gt;\u0026gt; \u0026quot;$2/tableau.html\u0026quot; numeroTable=$((numeroTable+1)); done echo \u0026quot;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; \u0026gt;\u0026gt; \u0026quot;$2/tableau.html\u0026quot;;  ","date":1571781600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571781600,"objectID":"d25ee74feef451d187a06b12d7e25e7e","permalink":"/projet_encadre/blog/4/","publishdate":"2019-10-23T00:00:00+02:00","relpermalink":"/projet_encadre/blog/4/","section":"blog","summary":"Pour conclure ce que nous avons fait les trois dernières séances :  Nous avons établi d’abord des tables de base contenant des URLs. Ce qui est réalisé à l’aide de deux boucles for, une pour parcourir tous nos fichiers d’URLs et construire une table pour chaque fichier, soit chaque langue ainsi que la deuxième servant à lire les URLs et les écrire dans nos tables ligne à ligne. Nous avons appris que le shell utilise des variables d’environnement dont l’on peut faire apparaître le contenu avec le signe dollars “$”.","tags":null,"title":"Cours 6 - Détection de l’encodage d’URL","type":"docs"},{"authors":null,"categories":null,"content":"Désormais, au moment de lancement de notre programme, nous devons mettre 3 arguments. Le premier et le deuxième sont respectivement le répertoire de l\u0026rsquo;input URL et celui de l\u0026rsquo;output tableau. Maintenant, le troisième est nos mots ciblés dans ce projet qui est donc \u0026lsquo;guerre commerciale|trade war|贸易战\u0026rsquo; pour nous. Ce troisième argument sert à compter sa fréquence dans le texte.\n\nLes 4 colonnes rajoutées sont :\n le contexte de mot-clé sa fréquence dans chaque fichier dump l\u0026rsquo;index des mots présents dans chaque fichier dump les bigrammes  \nMinigrep ou egrep\nAprès avoir intallé Perl, nous avons deux façons de trouver le contexte des mots ciblés, soit deux lignes autour de la ligne concernant les mots-clés, une avec egrep et une autre avec minigrep # ----06/11 # METHODE 1 : trouver la ligne avant et la ligne après de la ligne contenant notre mot-clé avec egrep # egrep -i -C 2 $motif '../DUMP-TEXT/$numerotableau-$compteur.txt' \u0026gt; '../CONTEXTES/$numerotableau-$compteur.txt'; # METHODE 2 : en utilisant minigrep # mettre les motifs dans le fichier parametre-motif.txt minigrep/minigrepmultilingue.pl \u0026quot;UTF-8\u0026quot; '../DUMP-TEXT/$numerotableau-$compteur.txt' minigrep/parametre-motif.txt; # renommer le fichier obtenu mv resultat-extraction.html ../CONTEXTES/$numerotableau-$compteur.html  Afin d\u0026rsquo;obtenir des bigrammes, nous avons concaténé tous les mots d\u0026rsquo;un fichier avec tous les mots de ce fichier sauf le premier en utilisant paste. Cependant, la manière dont on utilise pour récupérer des mots ne s\u0026rsquo;applique pas au chinois à cause du fait que le chinois n\u0026rsquo;utilise pas des délimiteurs pour distinguer des mots. Il nous faut donc trouver un autre outil pour la segmentation du corpus chinois.  # \\w+ ne marche que dans UTF-8 # INDEX DES MOTS egrep -o '\\w+' '../DUMP-TEXT/$numerotableau-$compteur.txt' | sort | uniq -c|sort -gr \u0026gt; '../DUMP-TEXT/index-$numerotableau-$compteur.txt'; ## BIGRAMS egrep -o '\\w+' '../DUMP-TEXT/$numerotableau-$compteur.txt' \u0026gt;fic1; tail -n +2 fich1 \u0026gt;fic2; paste fic1 fic2 | sort | uniq -c | sort -gr \u0026gt; '../DUMP-TEXT/bigrams-$numerotableau-$compteur.txt' ## COMPTER LE MOTIF frqMotif=$(egrep -oc $motif '../DUMP-TEXT/$numerotableau-$compteur.txt');  \nStanford Chinese Segmenter\nGrâce aux blogs de nos anciens camarades, nous avons connu un outil de segmentation du chinois à savoir Stanford Chinese Segmenter. En ce qui concerne l\u0026rsquo;usage de cet outil, tout est clair sur son site (https://nlp.stanford.edu/software/segmenter.shtml)[https://nlp.stanford.edu/software/segmenter.shtml] \nsh ./stanford-segmenter/segment.sh -k ctb ./DUMP-TEXT/*.txt utf-8 0  ","date":1572994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572994800,"objectID":"98258f7ceffb451ca7b1d447f01f95c1","permalink":"/projet_encadre/blog/5/","publishdate":"2019-11-06T00:00:00+01:00","relpermalink":"/projet_encadre/blog/5/","section":"blog","summary":"Désormais, au moment de lancement de notre programme, nous devons mettre 3 arguments. Le premier et le deuxième sont respectivement le répertoire de l\u0026rsquo;input URL et celui de l\u0026rsquo;output tableau. Maintenant, le troisième est nos mots ciblés dans ce projet qui est donc \u0026lsquo;guerre commerciale|trade war|贸易战\u0026rsquo; pour nous. Ce troisième argument sert à compter sa fréquence dans le texte.\n\nLes 4 colonnes rajoutées sont :\n le contexte de mot-clé sa fréquence dans chaque fichier dump l\u0026rsquo;index des mots présents dans chaque fichier dump les bigrammes","tags":null,"title":"Cours 7 - Rajouter 4 colonnes dans la table d'URLs","type":"docs"},{"authors":null,"categories":null,"content":"Lors de la détection de l\u0026rsquo;encodage, pour quelques URLs chinois, nous avons détecté TEXT/HTML comme résultat, ce qui n\u0026rsquo;était pas un type d\u0026rsquo;encodage et évidemment ne pouvait pas être converti en UTF-8 avec iconv. Il nous faut donc reconstruire nos codes selon le processus ci-après :\n\n","date":1572994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572994800,"objectID":"78d8af5e42305039d3b1e34d571c3031","permalink":"/projet_encadre/blog/6/","publishdate":"2019-11-06T00:00:00+01:00","relpermalink":"/projet_encadre/blog/6/","section":"blog","summary":"Lors de la détection de l\u0026rsquo;encodage, pour quelques URLs chinois, nous avons détecté TEXT/HTML comme résultat, ce qui n\u0026rsquo;était pas un type d\u0026rsquo;encodage et évidemment ne pouvait pas être converti en UTF-8 avec iconv. Il nous faut donc reconstruire nos codes selon le processus ci-après :","tags":null,"title":"Cours 8 - Résolution du problème d'encodage","type":"docs"},{"authors":null,"categories":null,"content":"Pour la segmentation du corpus chinois, la semaine dernière, nous avons utilisé le stanford-segmenter. Ayant pour but de le comparer avec un module Jieba qui se concentre sur la segmentation du texte chinois, nous avons écrit un script python en important ce dernier module pour réaliser la segmentation. \n\n#!/usr/bin/python # _*_ coding: utf-8 _*_ # segment chinese text # modules import re import sys import jieba # functions def tokenize(file): # input file with open(file, 'r', encoding='utf-8') as f: content = f.read() # clean text and keep only chinese characters pattern=re.compile(u'[^\\u4E00-\\u9FA5]') texte=pattern.sub(r'', content) wordlist_temp=list(jieba.cut(texte, cut_all=False)) wordlist=[i.rstrip() for i in wordlist_temp if len(i)\u0026gt;=1] return wordlist def token_file(file): wordlist=tokenize(sys.argv[1]) # output file with open(file, 'w', encoding='utf-8') as f: f.write(' '.join(wordlist)) if __name__ == \u0026quot;__main__\u0026quot;: token_file(sys.argv[2])  \nIl suffit de taper le nom du fichier contenant des textes chinois comme le premier argument et le nom du fichier de sortie comme le deuxième argument. python3.7 seg_jieba.py ../DUMP-TEXT/1-16.txt test1.txt  \nNous avons ensuite fait un test en prenant un de nos dump textes comme l\u0026rsquo;input avec les segmenteurs Jieba et Stanford-Segmenter. Les résultats sont affichés ci-après. Le résultat de Jieba s\u0026rsquo;affiche en haut tandis que celui de Stanford se trouve en bas.  ","date":1572994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572994800,"objectID":"2f9425d6b16a5b978d42c59ea483741d","permalink":"/projet_encadre/blog/7/","publishdate":"2019-11-06T00:00:00+01:00","relpermalink":"/projet_encadre/blog/7/","section":"blog","summary":"Pour la segmentation du corpus chinois, la semaine dernière, nous avons utilisé le stanford-segmenter. Ayant pour but de le comparer avec un module Jieba qui se concentre sur la segmentation du texte chinois, nous avons écrit un script python en important ce dernier module pour réaliser la segmentation. \n\n#!/usr/bin/python # _*_ coding: utf-8 _*_ # segment chinese text # modules import re import sys import jieba # functions def tokenize(file): # input file with open(file, 'r', encoding='utf-8') as f: content = f.","tags":null,"title":"Cours 9 - méthode 2 de de la segmentation du chinois","type":"docs"},{"authors":null,"categories":null,"content":"Pour que notre script final soit plus lisible et claire, nous essayons de remanier notre code en mettant chaque processus dans une fonction. Grâce au blog d\u0026rsquo;un ancien camarade, un exemple auquel on peut faire référence, nous avons pu comprendre le foctionnement des fonctions en bash dans un cas précis et concret. Voici le script principal.  #!/bin/bash # importer les fonctions . /Users/becca/Documents/nlp/coursS1/projetEncadre/PROJET-MOT-SUR-LE-WEB/PROGRAMMES/functions.sh #--------------------Main part-----------------# # on commence par supprimer l'éventuel fichier de résultat que l'on doit reconstruire rm -f \u0026quot;$2/tableau2.html\u0026quot; ; # on récupère les 2 arguments que l'on a passé au programme # le premier : chemin vers le dossier contenant les fichiers d'URL # le second : chemin vers le dossier devant contenir le fichier HTML final echo \u0026quot;Les urls SONT DANS : $1\u0026quot; ; echo \u0026quot;On créé le tableau HTML dans : $2\u0026quot; ; # output=$($2/tableau2.html) ecrireMetaData $2/tableau2.html # Création d'une variable pour compter les fichiers traités et donc le nb de tableau généré numerotableau=1; # Création d'une variable pour stocker notre terme ciblé motif=$3; # Parcours du dossier contenant les fichiers URLs for fichier in $(ls $1) do compteur=1; # compteur destiné à compter les URLs pour chaque fichier d'URL echo \u0026quot;$1/$fichier\u0026quot; ; #----------------------------------------------------------- # Création du tableau associé au fichier en cours de traitement #----------------------------------------------------------- ecrireTitre $2/tableau2.html # \u0026quot;parcours\u0026quot; d'un fichier d'URL : lecture ligne à ligne des URLs for ligne in $(cat \u0026quot;$1/$fichier\u0026quot;) do codeRetour=$(detHttpCode $ligne); if [[ $codeRetour == 200 ]] then encodage=$(detEncodage1 $ligne); curl -L -o \u0026quot;../PAGES-ASPIREES/$numerotableau-$compteur.html\u0026quot; \u0026quot;$ligne\u0026quot;; echo \u0026quot;ENCODAGE DETECTE PAR CURL : $encodage\u0026quot;; if [[ $encodage == \u0026quot;UTF-8\u0026quot; ]] then procUtf8 $2/tableau2.html else # http_code=200, l'encodage n'est pas utf-8 encodage=$(detEncodage2 $ligne) if [[ $encodage == \u0026quot;UTF-8\u0026quot; ]] then procUtf8 $2/tableau2.html else code=$(iconv -l|egrep -i $encodage) if [[ $code=true ]] then iconv -f $encodage -t 'utf-8' ../DUMP-TEXT/$numerotableau-$compteur.txt \u0026gt; ../DUMP-TEXT/$numerotableau-$compteur-converti.txt else procVide $2/tableau2.html fi fi fi else procVide $2/tableau2.html fi compteur=$((compteur+1)) ; done echo \u0026quot;\u0026lt;/table\u0026gt;\u0026lt;br /\u0026gt;\u0026quot; \u0026gt;\u0026gt; $2/tableau2.html ; # on incrémente le compteur de tableaux numerotableau=$((numerotableau+1)); done echo \u0026quot;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026quot; \u0026gt;\u0026gt; $2/tableau2.html ;  \n## functions # 1 html head ecrireMetaData(){ echo \u0026quot;\u0026lt;!DOCTYPE html\u0026gt;\u0026quot; \u0026gt; $1 echo \u0026quot;\u0026lt;html lang=\\\u0026quot;en\\\u0026quot;\u0026gt;\u0026quot; \u0026gt;\u0026gt; $1 echo \u0026quot;\u0026lt;head\u0026gt;\u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt;\u0026lt;title\u0026gt;Projet Encadre\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026quot; \u0026gt;\u0026gt; $1 echo \u0026quot;\u0026lt;body\u0026gt;\u0026quot; \u0026gt;\u0026gt; $1 } # 2 table title ecrireTitre(){ echo \u0026quot;\u0026lt;table border=\\\u0026quot;2\\\u0026quot; align=\\\u0026quot;center\\\u0026quot; width=\\\u0026quot;80%\\\u0026quot;\u0026gt;\u0026quot; \u0026gt;\u0026gt; $1 echo \u0026quot;\u0026lt;tr bgcolor=\\\u0026quot;grey\\\u0026quot;\u0026gt;\u0026lt;td\u0026gt;N°\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;URL\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Code http\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;encodage\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Page aspirée\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Dump\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Filtrage Txt\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Filtrage Html\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Index\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Bitexte\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;Fq Motif\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026quot; \u0026gt;\u0026gt; $1 } # 3 get http_code detHttpCode(){ curl -SIL -o toto -w \u0026quot;%{http_code}\u0026quot; $1 } # 4 two ways to get encoding detEncodage1(){ curl -sIL -o toto -w %{content_type} $1 | cut -f2 -d\u0026quot;=\u0026quot; | tr '[a-z]' '[A-Z]' | tr -d '\\r' } detEncodage2(){ egrep -oi 'charset=\u0026quot;?[^\u0026quot;,]+\u0026quot;?' $1 | cut -f2 -d\u0026quot;=\u0026quot; | tr '[a-z]' '[A-Z]' | tr -d '\\r'| head -1 } # 5 process text when encoding is utf-8 procUtf8(){ # 1. On lynx la page aspirée lynx -dump -nolist -assume_charset=$encodage -display_charset=$encodage \u0026quot;../PAGES-ASPIREES/$numerotableau-$compteur.html\u0026quot; \u0026gt; ../DUMP-TEXT/$numerotableau-$compteur.txt; #----------------------------------------------------------- # 2. On cree le fichier contexte TXT via egrep egrep -i -C2 \u0026quot;$motif\u0026quot; ../DUMP-TEXT/$numerotableau-$compteur.txt \u0026gt; ../CONTEXTE/$numerotableau-$compteur.txt; #----------------------------------------------------------- # 3. Fq motif nbmotif=$(egrep -coi \u0026quot;$motif\u0026quot; ../DUMP-TEXT/$numerotableau-$compteur.txt;); #----------------------------------------------------------- # 4. contexte html ../minigrep/minigrepmultilingue.pl \u0026quot;utf-8\u0026quot; ../DUMP-TEXT/$numerotableau-$compteur.txt ../minigrep/motif-regexp.txt ; mv resultat-extraction.html ../CONTEXTES/$numerotableau-$compteur.html ; #----------------------------------------------------------- # 5. index hierarchique egrep -o \u0026quot;\\w+\u0026quot; ../DUMP-TEXT/$numerotableau-$compteur.txt | sort | uniq -c | sort -r \u0026gt; ../DUMP-TEXT/index-$numerotableau-$compteur.txt ; #----------------------------------------------------------- # 6. bigramme egrep -o \u0026quot;\\w+\u0026quot; ../DUMP-TEXT/$numerotableau-$compteur.txt \u0026gt; bi1.txt; tail -n +2 bi1.txt \u0026gt; bi2.txt ; paste bi1.txt bi2.txt \u0026gt; bi3.txt ; cat bi3.txt | sort | uniq -c | sort -r \u0026gt; ../DUMP-TEXT/bigramme-$numerotableau-$compteur.txt ; #----------------------------------------------------------- # 7. on écrit les résultats dans le tableau avec tous les résultats produits echo \u0026quot;\u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;$compteur\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;$ligne\\\u0026quot; target=\\\u0026quot;_blank\\\u0026quot;\u0026gt;$ligne\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Code_http:$codeRetour\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Encodage:$encodage\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../PAGES-ASPIREES/$numerotableau-$compteur.html\\\u0026quot;\u0026gt;$numerotableau-$compteur.html\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../DUMP-TEXT/$numerotableau-$compteur.txt\\\u0026quot;\u0026gt;$numerotableau-$compteur.txt\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../CONTEXTES/$numerotableau-$compteur.txt\\\u0026quot;\u0026gt;$numerotableau-$compteur.txt\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../CONTEXTES/$numerotableau-$compteur.html\\\u0026quot;\u0026gt;$numerotableau-$compteur.html\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../DUMP-TEXT/index-$numerotableau-$compteur.txt\\\u0026quot;\u0026gt;index-$numerotableau-$compteur\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../DUMP-TEXT/bigramme-$numerotableau-$compteur.txt\\\u0026quot;\u0026gt;bigramme-$numerotableau-$compteur\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;$nbmotif\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt;\u0026quot; \u0026gt;\u0026gt; \u0026quot;$1\u0026quot; } # 6 write \u0026quot;-\u0026quot; in table procVide(){ echo \u0026quot;\u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;$compteur\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;$ligne\\\u0026quot; target=\\\u0026quot;_blank\\\u0026quot;\u0026gt;$ligne\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Code_http:$codeRetour\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;Encodage:$encodage\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\\\u0026quot;../PAGES-ASPIREES/$numerotableau-$compteur.html\\\u0026quot;\u0026gt;$numerotableau-$compteur.html\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;-\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026quot; \u0026gt;\u0026gt; \u0026quot;$1\u0026quot; }  ","date":1572994800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572994800,"objectID":"5617278c3fe29604092202990dbc88fd","permalink":"/projet_encadre/blog/8/","publishdate":"2019-11-06T00:00:00+01:00","relpermalink":"/projet_encadre/blog/8/","section":"blog","summary":"Pour que notre script final soit plus lisible et claire, nous essayons de remanier notre code en mettant chaque processus dans une fonction. Grâce au blog d\u0026rsquo;un ancien camarade, un exemple auquel on peut faire référence, nous avons pu comprendre le foctionnement des fonctions en bash dans un cas précis et concret. Voici le script principal.  #!/bin/bash # importer les fonctions . /Users/becca/Documents/nlp/coursS1/projetEncadre/PROJET-MOT-SUR-LE-WEB/PROGRAMMES/functions.sh #--------------------Main part-----------------# # on commence par supprimer l'éventuel fichier de résultat que l'on doit reconstruire rm -f \u0026quot;$2/tableau2.","tags":null,"title":"Cours 10 - Reconstruction du code (Refactoring)","type":"docs"}]